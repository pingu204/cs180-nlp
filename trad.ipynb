{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a7e4a65",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6a9bfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\documents\\github\\cs180-nlp\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\lenovo\\documents\\github\\cs180-nlp\\.venv\\lib\\site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\documents\\github\\cs180-nlp\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\documents\\github\\cs180-nlp\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\documents\\github\\cs180-nlp\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\documents\\github\\cs180-nlp\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lenovo\\documents\\github\\cs180-nlp\\.venv\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\lenovo\\documents\\github\\cs180-nlp\\.venv\\lib\\site-packages (from scikit-learn) (2.2.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\lenovo\\documents\\github\\cs180-nlp\\.venv\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\lenovo\\documents\\github\\cs180-nlp\\.venv\\lib\\site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\lenovo\\documents\\github\\cs180-nlp\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37fe2650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports and dependencies\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4b1281",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34524afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Removes unnecessary symbols from the text \"\"\"\n",
    "\n",
    "\n",
    "def clean_text(s: str):\n",
    "    # Only retain alphanumeric and whitespace characters\n",
    "    s = re.sub(pattern=rf\"|[^a-zA-Z0-9\\s]\", repl=\"\", string=s, flags=re.IGNORECASE)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    s = s.lower()\n",
    "\n",
    "    # Remove extra whitespaces\n",
    "    s = re.sub(pattern=r\"\\s+\", repl=\" \", string=s).strip()\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "\"\"\" Implements pipeline of pre-processing techniques \"\"\"\n",
    "\n",
    "\n",
    "def preprocess(text: str):\n",
    "    return clean_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58862c81",
   "metadata": {},
   "source": [
    "# Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9a36c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>− Scope 3: Optional scope that includes indire...</td>\n",
       "      <td>1</td>\n",
       "      <td>scope 3 optional scope that includes indirect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Group is not aware of any noise pollution ...</td>\n",
       "      <td>0</td>\n",
       "      <td>the group is not aware of any noise pollution ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Global climate change could exacerbate certain...</td>\n",
       "      <td>0</td>\n",
       "      <td>global climate change could exacerbate certain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Setting an investment horizon is part and parc...</td>\n",
       "      <td>0</td>\n",
       "      <td>setting an investment horizon is part and parc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Climate change the physical impacts of climate...</td>\n",
       "      <td>0</td>\n",
       "      <td>climate change the physical impacts of climate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Greenhouse gas Mitigation Measures Our five ye...</td>\n",
       "      <td>1</td>\n",
       "      <td>greenhouse gas mitigation measures our five ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>We have updated our external sector statements...</td>\n",
       "      <td>1</td>\n",
       "      <td>we have updated our external sector statements...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>STOREBRAND'S USE Task Force on Climate-related...</td>\n",
       "      <td>0</td>\n",
       "      <td>storebrands use task force on climaterelated f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Estimations of nanced emissions indicate the i...</td>\n",
       "      <td>1</td>\n",
       "      <td>estimations of nanced emissions indicate the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Emissions of CH4, which account for approximat...</td>\n",
       "      <td>1</td>\n",
       "      <td>emissions of ch4 which account for approximate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label  \\\n",
       "0    − Scope 3: Optional scope that includes indire...      1   \n",
       "1    The Group is not aware of any noise pollution ...      0   \n",
       "2    Global climate change could exacerbate certain...      0   \n",
       "3    Setting an investment horizon is part and parc...      0   \n",
       "4    Climate change the physical impacts of climate...      0   \n",
       "..                                                 ...    ...   \n",
       "995  Greenhouse gas Mitigation Measures Our five ye...      1   \n",
       "996  We have updated our external sector statements...      1   \n",
       "997  STOREBRAND'S USE Task Force on Climate-related...      0   \n",
       "998  Estimations of nanced emissions indicate the i...      1   \n",
       "999  Emissions of CH4, which account for approximat...      1   \n",
       "\n",
       "                                               cleaned  \n",
       "0    scope 3 optional scope that includes indirect ...  \n",
       "1    the group is not aware of any noise pollution ...  \n",
       "2    global climate change could exacerbate certain...  \n",
       "3    setting an investment horizon is part and parc...  \n",
       "4    climate change the physical impacts of climate...  \n",
       "..                                                 ...  \n",
       "995  greenhouse gas mitigation measures our five ye...  \n",
       "996  we have updated our external sector statements...  \n",
       "997  storebrands use task force on climaterelated f...  \n",
       "998  estimations of nanced emissions indicate the i...  \n",
       "999  emissions of ch4 which account for approximate...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training dataset\n",
    "file_path = \"data/train.json1\"\n",
    "\n",
    "data = []\n",
    "with open(file_path, \"r\") as f:\n",
    "    # Each line in `train.json1` corresponds to a record\n",
    "    for line in f:\n",
    "        data.append(json.loads(line.strip()))\n",
    "\n",
    "df = pd.json_normalize(data)\n",
    "\n",
    "df[\"cleaned\"] = df[\"text\"].apply(preprocess)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b49e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the vectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=0.05, max_df=0.85)\n",
    "\n",
    "X = vectorizer.fit_transform(df[\"cleaned\"])\n",
    "\n",
    "pickle.dump(vectorizer, open(\"vectorizer.sav\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bb14b2",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc519020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# Split into training and test sets\n",
    "X_train, y_train = X, df[\"label\"]\n",
    "# X_test, y_test =\n",
    "\n",
    "# Initialize MultinomialNB\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "filename = \"trad_model.sav\"\n",
    "pickle.dump(nb_model, open(filename, \"wb\"))\n",
    "\n",
    "# Load the model\n",
    "load_model = pickle.load(open(filename, \"rb\"))\n",
    "\n",
    "test_input = list(map(preprocess, [\"Climate change is a global issue.\"]))\n",
    "\n",
    "print(load_model.predict(vectorizer.transform(test_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba7c2165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74375\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84        53\n",
      "           1       0.75      0.80      0.77        81\n",
      "           2       0.50      0.31      0.38        26\n",
      "\n",
      "    accuracy                           0.74       160\n",
      "   macro avg       0.68      0.66      0.66       160\n",
      "weighted avg       0.73      0.74      0.73       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"data/dev.csv\")\n",
    "df_test[\"cleaned\"] = df_test[\"text\"].apply(preprocess)\n",
    "\n",
    "X_test, y_test = vectorizer.transform(df_test[\"cleaned\"]), df_test[\"label\"]\n",
    "y_pred = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300e71df",
   "metadata": {},
   "source": [
    "# Testing New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ba81d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: climate change is a global issue\n",
      "Predicted Label: Risk\n",
      "\n",
      "Text: green initiatives combat climate change\n",
      "Predicted Label: Opportunity\n",
      "\n",
      "Text: climate change affects everyone\n",
      "Predicted Label: Risk\n",
      "\n",
      "Text: global warming is alarming\n",
      "Predicted Label: Neutral\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# New data to test the model\n",
    "new_data = [\n",
    "    \"Climate change is a global issue.\",\n",
    "    \"Green initiatives combat climate change.\",\n",
    "    \"Climate change affects everyone.\",\n",
    "    \"Global warming is alarming.\",\n",
    "]\n",
    "\n",
    "new_data = list(map(lambda x: preprocess(x), new_data))\n",
    "\n",
    "# Preprocess and transform the new data\n",
    "new_X = vectorizer.transform(new_data)\n",
    "\n",
    "predictions = nb_model.predict(new_X)\n",
    "\n",
    "# Map the predictions to labels (if applicable)\n",
    "class_names = {0: \"Risk\", 1: \"Neutral\", 2: \"Opportunity\"}\n",
    "predicted_labels = [class_names[label] for label in predictions]\n",
    "\n",
    "# Display predictions\n",
    "for text, label in zip(new_data, predicted_labels):\n",
    "    print(f\"Text: {text}\\nPredicted Label: {label}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
